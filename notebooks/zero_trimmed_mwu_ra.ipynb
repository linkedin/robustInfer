{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a78021b-ffd0-41df-ac2e-46ea5c8dcadb",
   "metadata": {},
   "source": [
    "This notebook contains simulations for the Beyond Basic A/B Testing paper.\n",
    "\n",
    "There are two main sections of simulation:  zero-trimmed Mann-Whitney U-test (power and type I error rate comparison analysis) and regression adjustment (power comparison analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494b72b-e59d-4217-af72-1e77ebf3dc14",
   "metadata": {},
   "source": [
    "## Zero-trimmed Mann-Whitney U-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4272d0-eac1-4421-a386-c39b593163db",
   "metadata": {},
   "source": [
    "Data generating process:\n",
    "\n",
    "$y_{0i} =(1-D_i)y_{0i}'$, where $D_i \\sim \\textrm{Bernoulli}(p_0)$ and $y_{0i}' \\sim f(0, \\sigma)$. And $y_{1j} =(1-D_j)y_{1j}'$  where $D_j \\sim \\textrm{Bernoulli}(p_0 +p_{\\Delta})$ and $y_{1j}' \\sim f(\\mu, \\sigma)$ for $p_{\\Delta}, \\mu \\geq 0$. Here $f(\\cdot)$ denotes a heavy-tailed distribution (either LogNormal or Positive Cauchy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f32c7f4-d1ee-4427-be08-ff4da6db98bb",
   "metadata": {
    "execution_time": {
     "end_time": "2025-05-09T04:21:51.810325Z",
     "start_time": "2025-05-09T04:16:27.343615Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2da86e-5a29-49b5-8773-5454e4031992",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b722a5-9102-42ba-ac61-687c688c8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions\n",
    "def modified_wilcoxon(x, y):\n",
    "    \"\"\"Modified Wilcoxon test for zero-inflated data\"\"\"\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    n0, n1 = len(x), len(y)\n",
    "\n",
    "    # Assert that all input values are positive\n",
    "    assert np.all(x >= 0), \"All values in x must be non-negative.\"\n",
    "    assert np.all(y >= 0), \"All values in y must be non-negative.\"\n",
    "    assert n0 > 0 and n1 > 0, \"Both input arrays must be non-empty.\"\n",
    "    \n",
    "    # Calculate non-zero proportions\n",
    "    p_hat0 = np.sum(x > 0) / n0 if n0 > 0 else 0\n",
    "    p_hat1 = np.sum(y > 0) / n1 if n1 > 0 else 0\n",
    "    p_hat = max(p_hat0, p_hat1)\n",
    "    \n",
    "    # Truncate zeros\n",
    "    x_nonzero, y_nonzero = x[x > 0], y[y > 0]\n",
    "    n_plus0, n_plus1 = len(x_nonzero), len(y_nonzero)\n",
    "    n_prime_0, n_prime_1 = round(n0 * p_hat), round(n1 * p_hat)\n",
    "    \n",
    "    # Add zeros to balance proportions\n",
    "    x_trun = np.concatenate([np.zeros(int(n_prime_0) - len(x_nonzero)), x_nonzero])\n",
    "    y_trun = np.concatenate([np.zeros(int(n_prime_1) - len(y_nonzero)), y_nonzero])\n",
    "    \n",
    "    # Compute ranks and statistic\n",
    "    combined = np.concatenate([y_trun, x_trun])\n",
    "    descending_ranks = stats.rankdata(-combined, method='average')\n",
    "    R1 = np.sum(descending_ranks[:len(y_trun)])\n",
    "    W = R1 - len(y_trun) * (len(combined) + 1) / 2\n",
    "    \n",
    "    # Calculate variance\n",
    "    var_comp1 = (n1**2 * n0**2 / 4) * (p_hat**2) * (\n",
    "        (p_hat0 * (1 - p_hat0) / n0) + (p_hat1 * (1 - p_hat1) / n1)\n",
    "    )\n",
    "    var_comp2 = (n_plus0 * n_plus1 * (n_plus0 + n_plus1)) / 12\n",
    "    var_W = var_comp1 + var_comp2\n",
    "    \n",
    "    # Calculate p-value\n",
    "    Z = W / np.sqrt(var_W)\n",
    "    return 2 * stats.norm.cdf(-abs(Z))\n",
    "\n",
    "def standard_wilcoxon(x, y, use_correction=False):\n",
    "    \"\"\"Standard Mann-Whitney U test\"\"\"\n",
    "    if use_correction:\n",
    "        try:\n",
    "            # scipy's implementation has tie adjustment by default\n",
    "            _, p = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "            return p\n",
    "        except ValueError:\n",
    "            print(\"Value Error in Standard Wilcoxon test\")\n",
    "            return 1.0\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    n0, n1 = len(x), len(y)\n",
    "\n",
    "    # Compute ranks and statistic\n",
    "    combined = np.concatenate([y, x])\n",
    "    descending_ranks = stats.rankdata(-combined, method='average')\n",
    "    R1 = np.sum(descending_ranks[:len(y)])\n",
    "    W = R1 - len(y) * (len(combined) + 1) / 2\n",
    "\n",
    "    var_W = (n1 * n0 * (n1 + n0 + 1)) / 12\n",
    "    Z = W / np.sqrt(var_W)\n",
    "    return 2 * stats.norm.cdf(-abs(Z))\n",
    "\n",
    "\n",
    "def t_test(x, y):\n",
    "    \"\"\"Welch's t-test\"\"\"\n",
    "    try:\n",
    "        _, p = stats.ttest_ind(x, y, equal_var=False)\n",
    "        return p\n",
    "    except:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1140e4-37d6-491c-9b00-80ab19aa459d",
   "metadata": {},
   "source": [
    "### Simulation util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb806270-2624-473c-b402-34342c419a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(x, y, bins=30, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot two distributions on the same graph using Seaborn.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x, y : array-like\n",
    "        The two samples to plot\n",
    "    bins : int\n",
    "        Number of bins for the histogram\n",
    "    figsize : tuple\n",
    "        Figure size (width, height) in inches\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create DataFrame for seaborn\n",
    "    df = pd.DataFrame({\n",
    "        'Value': np.concatenate([x, y]),\n",
    "        'Group': np.concatenate([np.repeat('Group X', len(x)), np.repeat('Group Y', len(y))])\n",
    "    })\n",
    "    \n",
    "    # Plot histograms with KDE\n",
    "    sns.histplot(data=df, x='Value', hue='Group', bins=bins, kde=True, alpha=0.5)\n",
    "    \n",
    "    # Add zero proportions to title\n",
    "    zero_prop_x = np.mean(x == 0)\n",
    "    zero_prop_y = np.mean(y == 0)\n",
    "    plt.title(f'Distribution Comparison\\nZeros: Group X = {zero_prop_x:.2f}, Group Y = {zero_prop_y:.2f}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Data generation function\n",
    "def generate_data(n, zero_prop_x, effect, dist_type, zero_prop_delta=0, sigma=5):\n",
    "    \"\"\"\n",
    "    Generate zero-inflated data with specified distribution and different zero proportions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n : int\n",
    "        Sample size for each group\n",
    "    zero_prop_x : float\n",
    "        Proportion of zeros in the x group (between 0 and 1)\n",
    "    effect : float\n",
    "        Location shift for y group\n",
    "    dist_type : str\n",
    "        Type of distribution (\"lognormal\" or \"positive_cauchy\")\n",
    "    zero_prop_delta : float\n",
    "        Difference in zero proportion for y group (can be positive or negative)\n",
    "        zero_prop_y = zero_prop_x + zero_prop_delta\n",
    "    sigma : float\n",
    "        Scale parameter for lognormal distribution\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    x, y : numpy arrays\n",
    "        Generated data for both groups\n",
    "    \"\"\"\n",
    "    # Validate inputs, ensure alternative are y > x\n",
    "    assert 0 <= zero_prop_x <= 1, \"zero_prop_x must be between 0 and 1\"\n",
    "    assert zero_prop_delta <= 0, \"zero_prop_delta must be non-positive, so that y has more positives than x\"\n",
    "    assert effect >= 0, \"effect must be non-negative, so that y is shifted positively from x\"\n",
    "    \n",
    "    # Calculate y group zero proportion, ensuring it stays between 0 and 1\n",
    "    zero_prop_y = np.clip(zero_prop_x + zero_prop_delta, 0, 1)\n",
    "    \n",
    "    # Generate masks for non-zero values\n",
    "    x_mask = np.random.random(n) > zero_prop_x\n",
    "    y_mask = np.random.random(n) > zero_prop_y\n",
    "    \n",
    "    x, y = np.zeros(n), np.zeros(n)\n",
    "    \n",
    "    if dist_type == \"lognormal\":\n",
    "        if np.sum(x_mask) > 0:\n",
    "            x[x_mask] = np.random.lognormal(0, sigma, np.sum(x_mask))\n",
    "        if np.sum(y_mask) > 0:\n",
    "            y[y_mask] = np.random.lognormal(effect, sigma, np.sum(y_mask))\n",
    "    else:  # positive cauchy\n",
    "        if np.sum(x_mask) > 0:\n",
    "            x[x_mask] = np.abs(np.random.standard_cauchy(np.sum(x_mask)))\n",
    "        if np.sum(y_mask) > 0:\n",
    "            y[y_mask] = np.abs(np.random.standard_cauchy(np.sum(y_mask)) + effect)\n",
    "            \n",
    "    return x, y\n",
    "    \n",
    "\n",
    "# Main simulation function\n",
    "def run_simulation(n_iter=5000):\n",
    "    # Configuration parameters\n",
    "    sample_sizes = [50, 200]\n",
    "    alpha = 0.05\n",
    "    distributions = [\"lognormal\", \"positive_cauchy\"]\n",
    "    base_zero_prop = 0.8\n",
    "    # zero_prop_deltas = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5] # Difference in zero proportion percentages\n",
    "    zero_prop_deltas = [0.0, -0.1]\n",
    "    base_effect_size = 0.0\n",
    "    effect_size_deltas = [0.0, 0.05, 1.0, 2.0]  # Location shifts\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for dist in distributions:\n",
    "        for sample_size in sample_sizes:\n",
    "            for zero_prop_delta in zero_prop_deltas:\n",
    "                for effect_size_delta in effect_size_deltas:\n",
    "                    print(f\"Running: dist={dist}, sample_size={sample_size}, zero_prop_delta={zero_prop_delta}, effect_size_delta={effect_size_delta}\")\n",
    "                    \n",
    "                    mod_rejects = 0\n",
    "                    std_rejects = 0\n",
    "                    t_rejects = 0\n",
    "                    \n",
    "                    for _ in range(n_iter):\n",
    "                        # Generate data\n",
    "                        zero_prop = base_zero_prop - zero_prop_delta\n",
    "                        effect_size = base_effect_size + effect_size_delta\n",
    "                        \n",
    "                        x, y = generate_data(sample_size, base_zero_prop, effect_size, dist, zero_prop_delta=zero_prop_delta, sigma=5)\n",
    "                        \n",
    "                        # Apply tests\n",
    "                        mod_p = modified_wilcoxon(x, y)\n",
    "                        std_p = standard_wilcoxon(x, y)\n",
    "                        t_p = t_test(x, y)\n",
    "                        \n",
    "                        # Count rejections\n",
    "                        mod_rejects += (mod_p < alpha)\n",
    "                        std_rejects += (std_p < alpha)\n",
    "                        t_rejects += (t_p < alpha)\n",
    "\n",
    "                    # Calculate rejection rates\n",
    "                    results.append({\n",
    "                        'sample_size': sample_size,\n",
    "                        'alpha': alpha,\n",
    "                        'distribution': dist,\n",
    "                        'positive_prop_x': 1-base_zero_prop,\n",
    "                        'postive_prop_delta': -zero_prop_delta,\n",
    "                        'effect_size': effect_size,\n",
    "                        'null_true': (effect_size == 0.0 and zero_prop_delta == 0.0),\n",
    "                        'modified_wilcoxon': mod_rejects / n_iter,\n",
    "                        'standard_wilcoxon': std_rejects / n_iter,\n",
    "                        't_test': t_rejects / n_iter\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa25b6-5c30-4e39-a835-957067ed45df",
   "metadata": {},
   "source": [
    "### Run the Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6860d49-2a5d-4f2b-9310-30501fda291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=0.0, effect_size_delta=0.0\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=0.0, effect_size_delta=0.05\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=0.0, effect_size_delta=1.0\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=0.0, effect_size_delta=2.0\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=0.0\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=0.05\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=1.0\n",
      "Running: dist=lognormal, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=2.0\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=0.0, effect_size_delta=0.0\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=0.0, effect_size_delta=0.05\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=0.0, effect_size_delta=1.0\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=0.0, effect_size_delta=2.0\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=0.0\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=0.05\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=1.0\n",
      "Running: dist=lognormal, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=2.0\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=0.0, effect_size_delta=0.0\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=0.0, effect_size_delta=0.05\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=0.0, effect_size_delta=1.0\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=0.0, effect_size_delta=2.0\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=0.0\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=0.05\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=1.0\n",
      "Running: dist=positive_cauchy, sample_size=50, zero_prop_delta=-0.1, effect_size_delta=2.0\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=0.0, effect_size_delta=0.0\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=0.0, effect_size_delta=0.05\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=0.0, effect_size_delta=1.0\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=0.0, effect_size_delta=2.0\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=0.0\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=0.05\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=1.0\n",
      "Running: dist=positive_cauchy, sample_size=200, zero_prop_delta=-0.1, effect_size_delta=2.0\n"
     ]
    }
   ],
   "source": [
    "# Run simulation and analyze results\n",
    "np.random.seed(42)\n",
    "\n",
    "# Run the simulation\n",
    "results = run_simulation(n_iter=1000)\n",
    "\n",
    "# Separate Type I error from power\n",
    "type1_error = results[results['null_true'] == True]\n",
    "power = results[results['null_true'] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67f9b72-860c-4aff-8cb2-fa6f77538de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type I Error Rates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>modified_wilcoxon</th>\n",
       "      <th>standard_wilcoxon</th>\n",
       "      <th>t_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <th>positive_prop_x</th>\n",
       "      <th>postive_prop_delta</th>\n",
       "      <th>sample_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">lognormal</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">-0.0</th>\n",
       "      <th>50</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">positive_cauchy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">-0.0</th>\n",
       "      <th>50</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               modified_wilcoxon  \\\n",
       "alpha                                                                       0.05   \n",
       "distribution    positive_prop_x postive_prop_delta sample_size                     \n",
       "lognormal       0.2             -0.0               50                      0.053   \n",
       "                                                   200                     0.055   \n",
       "positive_cauchy 0.2             -0.0               50                      0.062   \n",
       "                                                   200                     0.054   \n",
       "\n",
       "                                                               standard_wilcoxon  \\\n",
       "alpha                                                                       0.05   \n",
       "distribution    positive_prop_x postive_prop_delta sample_size                     \n",
       "lognormal       0.2             -0.0               50                      0.008   \n",
       "                                                   200                     0.003   \n",
       "positive_cauchy 0.2             -0.0               50                      0.004   \n",
       "                                                   200                     0.008   \n",
       "\n",
       "                                                               t_test  \n",
       "alpha                                                            0.05  \n",
       "distribution    positive_prop_x postive_prop_delta sample_size         \n",
       "lognormal       0.2             -0.0               50           0.000  \n",
       "                                                   200          0.003  \n",
       "positive_cauchy 0.2             -0.0               50           0.018  \n",
       "                                                   200          0.027  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Type I error results\n",
    "print(\"Type I Error Rates:\")\n",
    "type1_error.pivot_table(\n",
    "    index=['distribution', 'positive_prop_x', 'postive_prop_delta', 'sample_size'],\n",
    "    columns='alpha',\n",
    "    values=['modified_wilcoxon', 'standard_wilcoxon', 't_test']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ebaa5f5-ec43-4b1e-a9e8-ad35cc5582c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Power Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>modified_wilcoxon</th>\n",
       "      <th>standard_wilcoxon</th>\n",
       "      <th>t_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <th>positive_prop_x</th>\n",
       "      <th>postive_prop_delta</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>effect_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">lognormal</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">-0.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">50</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.070</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">200</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0.1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">50</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.209</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">200</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.539</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">positive_cauchy</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">-0.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">50</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">200</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.347</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0.1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">50</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.206</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.278</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">200</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.523</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           modified_wilcoxon  \\\n",
       "alpha                                                                                   0.05   \n",
       "distribution    positive_prop_x postive_prop_delta sample_size effect_size                     \n",
       "lognormal       0.2             -0.0               50          0.05                    0.063   \n",
       "                                                               1.00                    0.070   \n",
       "                                                               2.00                    0.077   \n",
       "                                                   200         0.05                    0.044   \n",
       "                                                               1.00                    0.069   \n",
       "                                                               2.00                    0.166   \n",
       "                                 0.1               50          0.00                    0.213   \n",
       "                                                               0.05                    0.209   \n",
       "                                                               1.00                    0.269   \n",
       "                                                               2.00                    0.325   \n",
       "                                                   200         0.00                    0.529   \n",
       "                                                               0.05                    0.539   \n",
       "                                                               1.00                    0.724   \n",
       "                                                               2.00                    0.851   \n",
       "positive_cauchy 0.2             -0.0               50          0.05                    0.066   \n",
       "                                                               1.00                    0.068   \n",
       "                                                               2.00                    0.122   \n",
       "                                                   200         0.05                    0.053   \n",
       "                                                               1.00                    0.104   \n",
       "                                                               2.00                    0.347   \n",
       "                                 0.1               50          0.00                    0.206   \n",
       "                                                               0.05                    0.212   \n",
       "                                                               1.00                    0.278   \n",
       "                                                               2.00                    0.475   \n",
       "                                                   200         0.00                    0.565   \n",
       "                                                               0.05                    0.523   \n",
       "                                                               1.00                    0.751   \n",
       "                                                               2.00                    0.955   \n",
       "\n",
       "                                                                           standard_wilcoxon  \\\n",
       "alpha                                                                                   0.05   \n",
       "distribution    positive_prop_x postive_prop_delta sample_size effect_size                     \n",
       "lognormal       0.2             -0.0               50          0.05                    0.004   \n",
       "                                                               1.00                    0.006   \n",
       "                                                               2.00                    0.001   \n",
       "                                                   200         0.05                    0.005   \n",
       "                                                               1.00                    0.004   \n",
       "                                                               2.00                    0.008   \n",
       "                                 0.1               50          0.00                    0.075   \n",
       "                                                               0.05                    0.085   \n",
       "                                                               1.00                    0.074   \n",
       "                                                               2.00                    0.100   \n",
       "                                                   200         0.00                    0.383   \n",
       "                                                               0.05                    0.381   \n",
       "                                                               1.00                    0.435   \n",
       "                                                               2.00                    0.499   \n",
       "positive_cauchy 0.2             -0.0               50          0.05                    0.004   \n",
       "                                                               1.00                    0.006   \n",
       "                                                               2.00                    0.002   \n",
       "                                                   200         0.05                    0.005   \n",
       "                                                               1.00                    0.005   \n",
       "                                                               2.00                    0.009   \n",
       "                                 0.1               50          0.00                    0.074   \n",
       "                                                               0.05                    0.066   \n",
       "                                                               1.00                    0.089   \n",
       "                                                               2.00                    0.129   \n",
       "                                                   200         0.00                    0.391   \n",
       "                                                               0.05                    0.370   \n",
       "                                                               1.00                    0.459   \n",
       "                                                               2.00                    0.601   \n",
       "\n",
       "                                                                           t_test  \n",
       "alpha                                                                        0.05  \n",
       "distribution    positive_prop_x postive_prop_delta sample_size effect_size         \n",
       "lognormal       0.2             -0.0               50          0.05         0.002  \n",
       "                                                               1.00         0.000  \n",
       "                                                               2.00         0.003  \n",
       "                                                   200         0.05         0.007  \n",
       "                                                               1.00         0.002  \n",
       "                                                               2.00         0.005  \n",
       "                                 0.1               50          0.00         0.002  \n",
       "                                                               0.05         0.003  \n",
       "                                                               1.00         0.003  \n",
       "                                                               2.00         0.005  \n",
       "                                                   200         0.00         0.006  \n",
       "                                                               0.05         0.006  \n",
       "                                                               1.00         0.021  \n",
       "                                                               2.00         0.035  \n",
       "positive_cauchy 0.2             -0.0               50          0.05         0.023  \n",
       "                                                               1.00         0.022  \n",
       "                                                               2.00         0.058  \n",
       "                                                   200         0.05         0.016  \n",
       "                                                               1.00         0.029  \n",
       "                                                               2.00         0.070  \n",
       "                                 0.1               50          0.00         0.053  \n",
       "                                                               0.05         0.047  \n",
       "                                                               1.00         0.085  \n",
       "                                                               2.00         0.198  \n",
       "                                                   200         0.00         0.077  \n",
       "                                                               0.05         0.068  \n",
       "                                                               1.00         0.139  \n",
       "                                                               2.00         0.251  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Power results - with option to display all rows\n",
    "# Set display options to show the full table\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Display Power results\n",
    "print(\"\\nPower Results:\")\n",
    "power.pivot_table(\n",
    "    index=['distribution', 'positive_prop_x', 'postive_prop_delta', 'sample_size', 'effect_size'],\n",
    "    columns='alpha',\n",
    "    values=['modified_wilcoxon', 'standard_wilcoxon', 't_test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b3261-3f90-4ced-83b3-69e4b6147676",
   "metadata": {},
   "source": [
    "## Regression Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d4e0f-532e-4d77-be34-8bc985c8344e",
   "metadata": {},
   "source": [
    "Data generating process:\n",
    "\n",
    "\n",
    "\n",
    "$$ w_i \\sim \\mathcal{N}(0,1),$$\n",
    "\n",
    "$$z_i|w_i \\sim \\textrm{Bernoulli}\\left( \\frac{1}{1+e^{-\\gamma w_i}} \\right),$$ \n",
    "\n",
    "$$y_i|z_i,w_i \\sim \\textrm{Poisson}\\left( e^{2 + \\beta_z z_i + \\beta_w w_i}\\right)$$\n",
    "\n",
    "\n",
    "Here $\\gamma \\geq 0$ controls the degree of confounding ($\\gamma = 0$ implies no confounding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40a347-ab42-4b2d-879a-4e5f89854f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde51cc-e8e2-4dcf-84ae-5b9ba7c73f50",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-29T19:15:15.498783Z",
     "start_time": "2025-04-29T19:11:38.310031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_data(n_samples, beta_t=0, beta_x=1, conf_strength=0.5):\n",
    "    \"\"\"Generate data with a Poisson outcome, treatment T, and confounder X\"\"\"\n",
    "    # Generate confounder X\n",
    "    X = np.random.normal(0, 1, n_samples)\n",
    "    \n",
    "    # Generate treatment with dependency on X (confounding)\n",
    "    p_treat = 1 / (1 + np.exp(-(conf_strength * X)))\n",
    "    T = np.random.binomial(1, p_treat, n_samples)\n",
    "    \n",
    "    # Generate Poisson outcome\n",
    "    lambda_i = np.exp(2 + beta_t * T + beta_x * X)\n",
    "    Y = np.random.poisson(lambda_i, n_samples)\n",
    "    \n",
    "    return pd.DataFrame({'Y': Y, 'T': T, 'X': X})\n",
    "\n",
    "def run_simulation(conf_strength, n_samples=200, n_sims=5000, alpha=0.05):\n",
    "    \"\"\"Run simulation and return Type I error rates\"\"\"\n",
    "    reject_unadj = 0\n",
    "    reject_adj = 0\n",
    "    \n",
    "    for _ in range(n_sims):\n",
    "        # Generate data under null hypothesis (beta_t = 0)\n",
    "        data = generate_data(n_samples, beta_t=0, beta_x=0.05, conf_strength=conf_strength)\n",
    "        \n",
    "        # Unadjusted model (raw test)\n",
    "        model_unadj = sm.GLM(data['Y'], sm.add_constant(data['T']), family=sm.families.Poisson())\n",
    "        results_unadj = model_unadj.fit(disp=0)\n",
    "        if results_unadj.pvalues[1] < alpha:\n",
    "            reject_unadj += 1\n",
    "        \n",
    "        # Adjusted model (regression adjustment)\n",
    "        model_adj = sm.GLM(data['Y'], sm.add_constant(pd.DataFrame({'T': data['T'], 'X': data['X']})), \n",
    "                          family=sm.families.Poisson())\n",
    "        results_adj = model_adj.fit(disp=0)\n",
    "        if results_adj.pvalues[1] < alpha:\n",
    "            reject_adj += 1\n",
    "    \n",
    "    # Calculate Type I error rates\n",
    "    type1_unadj = reject_unadj / n_sims\n",
    "    type1_adj = reject_adj / n_sims\n",
    "    \n",
    "    return type1_unadj, type1_adj\n",
    "\n",
    "# Confounding strengths to test\n",
    "conf_strengths = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "# Run simulations\n",
    "results = []\n",
    "for conf in conf_strengths:\n",
    "    print(f\"Running simulation with confounding strength = {conf}\")\n",
    "    type1_unadj, type1_adj = run_simulation(conf)\n",
    "    results.append([conf, type1_unadj, type1_adj])\n",
    "\n",
    "# Create results table\n",
    "results_df = pd.DataFrame(results, columns=['Confounding Strength', 'Type I Error (Raw)', 'Type I Error (RA)'])\n",
    "results_df['Inflation Factor'] = results_df['Type I Error (Raw)'] / 0.05\n",
    "\n",
    "print(\"\\nType I Error Comparison: Raw Test vs. Regression Adjustment\")\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_data(n_samples, beta_t, beta_x=1, conf_strength=0):\n",
    "    \"\"\"\n",
    "    Generate data with a Poisson outcome, treatment T, and predictor X\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: Number of observations\n",
    "    - beta_t: True treatment effect\n",
    "    - beta_x: Effect of X on outcome\n",
    "    - conf_strength: Strength of confounding (0 = no confounding)\n",
    "    \"\"\"\n",
    "    # Generate predictor X\n",
    "    X = np.random.normal(0, 1, n_samples)\n",
    "    \n",
    "    # Generate treatment with dependency on X (confounding strength controlled by conf_strength)\n",
    "    p_treat = 1 / (1 + np.exp(-(conf_strength * X)))\n",
    "    T = np.random.binomial(1, p_treat, n_samples)\n",
    "    \n",
    "    # Generate Poisson outcome\n",
    "    lambda_i = np.exp(2 + beta_t * T + beta_x * X)\n",
    "    Y = np.random.poisson(lambda_i, n_samples)\n",
    "    \n",
    "    return pd.DataFrame({'Y': Y, 'T': T, 'X': X})\n",
    "\n",
    "def calculate_power(n_samples, beta_t, beta_x=1, conf_strength=0, n_sims=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate power for both unadjusted and adjusted models\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: Number of observations\n",
    "    - beta_t: True treatment effect (non-zero for power calculation)\n",
    "    - beta_x: Effect of X on outcome\n",
    "    - conf_strength: Strength of confounding\n",
    "    - n_sims: Number of simulation runs\n",
    "    - alpha: Significance level\n",
    "    \n",
    "    Returns:\n",
    "    - Power for both models\n",
    "    \"\"\"\n",
    "    # Store rejection indicators\n",
    "    reject_unadj = 0\n",
    "    reject_adj = 0\n",
    "    \n",
    "    for _ in range(n_sims):\n",
    "        # Generate data with specified confounding and treatment effect\n",
    "        data = generate_data(n_samples, beta_t=beta_t, beta_x=beta_x, conf_strength=conf_strength)\n",
    "        \n",
    "        # Unadjusted model (raw test)\n",
    "        model_unadj = sm.GLM(data['Y'], sm.add_constant(data['T']), family=sm.families.Poisson())\n",
    "        results_unadj = model_unadj.fit(disp=0)\n",
    "        if results_unadj.pvalues[1] < alpha:\n",
    "            reject_unadj += 1\n",
    "        \n",
    "        # Adjusted model (regression adjustment)\n",
    "        model_adj = sm.GLM(data['Y'], \n",
    "                          sm.add_constant(pd.DataFrame({'T': data['T'], 'X': data['X']})), \n",
    "                          family=sm.families.Poisson())\n",
    "        results_adj = model_adj.fit(disp=0)\n",
    "        if results_adj.pvalues[1] < alpha:\n",
    "            reject_adj += 1\n",
    "    \n",
    "    # Calculate power\n",
    "    power_unadj = reject_unadj / n_sims\n",
    "    power_adj = reject_adj / n_sims\n",
    "    \n",
    "    return power_unadj, power_adj\n",
    "\n",
    "# Configuration for power simulations\n",
    "effect_sizes = [0.1 + 0.01*i for i in range(0, 11)]\n",
    "n_samples = 200\n",
    "n_sims = 1000\n",
    "conf_strengths = [0.0, 0.1]  # No confounding and moderate confounding\n",
    "\n",
    "# Run comprehensive simulations\n",
    "results = []\n",
    "for conf in conf_strengths:\n",
    "    conf_label = \"No Confounding\" if conf == 0.0 else \"With Confounding\"\n",
    "    print(f\"\\nRunning simulations for {conf_label} (conf_strength = {conf})\")\n",
    "    \n",
    "    for effect in effect_sizes:\n",
    "        print(f\"  Effect size: {effect}\")\n",
    "        power_unadj, power_adj = calculate_power(\n",
    "            n_samples=n_samples, \n",
    "            beta_t=effect, \n",
    "            beta_x=1.0, \n",
    "            conf_strength=conf,\n",
    "            n_sims=n_sims\n",
    "        )\n",
    "        \n",
    "        # Store results with all details\n",
    "        results.append({\n",
    "            'Confounding': conf_label,\n",
    "            'Confounding Strength': conf,\n",
    "            'Treatment Effect': effect,\n",
    "            'Power (Raw)': power_unadj,\n",
    "            'Power (RA)': power_adj,\n",
    "            'Power Difference': power_adj - power_unadj,\n",
    "            'Relative Improvement': ((power_adj / power_unadj) - 1) * 100 if power_unadj > 0 else float('inf')\n",
    "        })\n",
    "\n",
    "# Create comprehensive results table\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print formatted table\n",
    "print(\"\\nPower Comparison: Raw Test vs. Regression Adjustment\")\n",
    "print(f\"Sample Size: {n_samples}, Simulations: {n_sims}\")\n",
    "\n",
    "# Group by confounding status for clearer presentation\n",
    "for conf_label in [\"No Confounding\", \"With Confounding\"]:\n",
    "    subset = results_df[results_df['Confounding'] == conf_label]\n",
    "    print(f\"\\n{conf_label} (Î³ = {subset['Confounding Strength'].iloc[0]}):\")\n",
    "    \n",
    "    formatted_subset = subset[['Treatment Effect', 'Power (Raw)', 'Power (RA)', 'Power Difference']]\n",
    "    print(formatted_subset.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# LaTeX table format for the comprehensive results\n",
    "print(\"\\nLaTeX Table Format:\")\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{table}[htbp]\n",
    "\\\\centering\n",
    "\\\\begin{tabular}{cccccc}\n",
    "\\\\hline\n",
    "Confounding ($\\\\gamma$) & Treatment Effect ($\\\\beta_T$) & Power (Raw) & Power (RA) & Difference & Improvement (\\\\%) \\\\\\\\\n",
    "\\\\hline\"\"\"\n",
    "\n",
    "for conf in conf_strengths:\n",
    "    subset = results_df[results_df['Confounding Strength'] == conf]\n",
    "    for _, row in subset.iterrows():\n",
    "        latex_table += f\"\\n{row['Confounding Strength']} & {row['Treatment Effect']:.1f} & {row['Power (Raw)']:.4f} & {row['Power (RA)']:.4f} & {row['Power Difference']:.4f} & {row['Relative Improvement']:.1f} \\\\\\\\\"\n",
    "    \n",
    "    # Add a separator between confounding scenarios\n",
    "    if conf == 0.0:\n",
    "        latex_table += \"\\n\\\\hline\"\n",
    "\n",
    "latex_table += \"\"\"\n",
    "\\\\hline\n",
    "\\\\end{tabular}\n",
    "\\\\caption{Power Comparison: Raw Test vs. Regression Adjustment}\n",
    "\\\\label{tab:power}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot for No Confounding\n",
    "no_conf = results_df[results_df['Confounding'] == \"No Confounding\"]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(no_conf['Treatment Effect'], no_conf['Power (Raw)'], 'bo-', label='Raw Test')\n",
    "plt.plot(no_conf['Treatment Effect'], no_conf['Power (RA)'], 'ro-', label='Regression Adjustment')\n",
    "plt.xlabel('Treatment Effect Size')\n",
    "plt.ylabel('Power')\n",
    "plt.title('Power Comparison: No Confounding (Î³ = 0)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Plot for With Confounding\n",
    "with_conf = results_df[results_df['Confounding'] == \"With Confounding\"]\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(with_conf['Treatment Effect'], with_conf['Power (Raw)'], 'bo-', label='Raw Test')\n",
    "plt.plot(with_conf['Treatment Effect'], with_conf['Power (RA)'], 'ro-', label='Regression Adjustment')\n",
    "plt.xlabel('Treatment Effect Size')\n",
    "plt.ylabel('Power')\n",
    "plt.title(f'Power Comparison: With Confounding (Î³ = {conf_strengths[1]})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('power_comparison_combined.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332756fc-0866-482a-95e7-454f11e567fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "darwin": {
   "resource_id": 14943481,
   "username": "bzelditc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
