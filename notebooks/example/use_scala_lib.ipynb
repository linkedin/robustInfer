{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc694e1b-49dd-46ac-8b33-484297e2ea9e",
   "metadata": {},
   "source": [
    "## load jar\n",
    "since we mount the repo to containder under /app, we have the abs path as: ```/app/scala_lib/build/libs/robustInfer-scala-0.1.0.jar```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c4fa34-9238-4816-bcf6-4a991157c937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:/app/scala_lib/build/libs/robustInfer-scala-0.1.0.jar\n",
      "Finished download of robustInfer-scala-0.1.0.jar\n",
      "Using cached version of robustInfer-scala-0.1.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:/app/scala_lib/build/libs/robustInfer-scala-0.1.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb692187-13a6-47c7-903e-6a298bb42349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import robustinfer._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c522208-f7cd-42be-984a-fb20f70d9795",
   "metadata": {},
   "source": [
    "## small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2204cf98-4afc-4e0a-b448-1367700fc9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating R at warm-up iteration 0\n",
      "Updating R at warm-up iteration 5\n",
      "Warm-up iterations completed: 10, converged: false\n",
      "Iteration: DenseVector(31.63248781163211, -42.916880238607014, 0.6267263792368888), ||delta|| = 4.607049104662032\n",
      "Iteration: DenseVector(34.069822921562334, -46.22160766010823, 0.6971014269323877), ||delta|| = 4.106918360018712\n",
      "Iteration: DenseVector(36.01035459506486, -48.903660252126606, 0.824488517978528), ||delta|| = 3.3128985425430977\n",
      "Iteration: DenseVector(37.42469655493082, -50.90668313410217, 0.9960910521533917), ||delta|| = 2.4580299580945746\n",
      "Iteration: DenseVector(38.69044404948559, -52.57841155139295, 0.9091657405574657), ||delta|| = 2.0986540045813373\n",
      "Iteration: DenseVector(39.681422130298905, -53.87345119464639, 0.8281467676034963), ||delta|| = 1.632706130394858\n",
      "Iteration: DenseVector(40.42548123186567, -54.82398666975567, 0.8018376396034246), ||delta|| = 1.2074078872865144\n",
      "Iteration: DenseVector(41.024309566724746, -55.585927402148684, 0.7910792495666288), ||delta|| = 0.9691567454575554\n",
      "Iteration: DenseVector(41.52865321281834, -56.2305676584053, 0.7830488284881303), ||delta|| = 0.818527984252384\n",
      "Iteration: DenseVector(41.963749368465606, -56.789359299274416, 0.7763104614450946), ||delta|| = 0.7082387790531091\n",
      "Main iterations completed: 10, converged: false\n",
      "GEE did not converge after 10 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data = List(Obs(1,[D@6c87a461,1.0,None,None), Obs(1,[D@10705c32,0.0,None,None), Obs(2,[D@63df7975,1.0,None,None), Obs(2,[D@44838f5,0.0,None,None))\n",
       "df = [i: string, x: array<double> ... 3 more fields]\n",
       "gee = robustinfer.GEE@1d60b598\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "EESummary(DenseVector(42.3430901452824, -57.28375103748985, 0.7671272123191027),0.2859845644832337    -0.3294780144074219  -0.09787819849504109\n",
       "-0.32947801440742197  0.3817841516317764   0.10814057735932561\n",
       "-0.0978781984950411   0.10814057735932567  0.043223025921816004  )\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "val data = Seq(\n",
    "  Obs(\"1\", Array(0.0, 1.0), 1.0),\n",
    "  Obs(\"1\", Array(1.0, -1.0), 0.0),\n",
    "  Obs(\"2\", Array(0.5, 0.5), 1.0),\n",
    "  Obs(\"2\", Array(1.0, 0.2), 0.0)\n",
    ")\n",
    "\n",
    "val df = spark.createDataset(data)\n",
    "\n",
    "val gee = new GEE(corStruct = Exchangeable)\n",
    "gee.fit(df)\n",
    "gee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da67aa38-90a5-449f-bd65-0b70e7bc9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-------------------+------------------+--------------------+\n",
      "|    names|              coef|                 se|                 z|             p-value|\n",
      "+---------+------------------+-------------------+------------------+--------------------+\n",
      "|intercept|  42.3430901452824| 0.5347752467001756| 79.17922605161691|                 0.0|\n",
      "|    beta1|-57.28375103748985| 0.6178868437115136|-92.70912889712727|                 0.0|\n",
      "|    beta2|0.7671272123191027|0.20790148128817168|3.6898592908810968|2.243781247428522...|\n",
      "+---------+------------------+-------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gee.dfSummary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d6a7c7-384b-4f2f-8431-eeee80dfe789",
   "metadata": {},
   "source": [
    "## Simulation (MWU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5285d70-c3ac-4271-b65e-19a3c4bf92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rng = scala.util.Random@6db74262\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "scala.util.Random@6db74262"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.commons.math3.distribution.CauchyDistribution\n",
    "import scala.util.Random\n",
    "val rng = new Random(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdaa434-e266-43f8-944a-fbf7a74f5e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "samplePositiveCauchy: (dist: org.apache.commons.math3.distribution.CauchyDistribution, n: Int)Seq[Double]\n",
       "simulationCauchy: (n: Int, diff: Double)(org.apache.spark.rdd.RDD[Double], org.apache.spark.rdd.RDD[Double])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.SparkContext\n",
    "\n",
    "def samplePositiveCauchy(dist: CauchyDistribution, n: Int): Seq[Double] =\n",
    "  Seq.fill(n)(math.max(0.0, dist.sample()))\n",
    "\n",
    "def simulationCauchy(n: Int, diff: Double): (RDD[Double], RDD[Double]) = {\n",
    "  val dist1 = new CauchyDistribution(0.0, 1.0)\n",
    "  val dist2 = new CauchyDistribution(diff, 1.0)\n",
    "    \n",
    "  val cauchy1 = samplePositiveCauchy(dist1, n)\n",
    "  val cauchy2 = samplePositiveCauchy(dist2, n)\n",
    "\n",
    "  val rdd1 = sc.parallelize(cauchy1)\n",
    "  val rdd2 = sc.parallelize(cauchy2)\n",
    "  (rdd1, rdd2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298f89f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runSimulation: (n: Int, diff: Double)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scala.collection.mutable.{ArrayBuffer, Map}\n",
    "\n",
    "def runSimulation(n: Int, diff: Double): Unit = {\n",
    "  val maxIter = 200\n",
    "  var iter = 0\n",
    "  val pValues = Map(\n",
    "    \"tTest\" -> ArrayBuffer[Double](),\n",
    "    \"mwU\" -> ArrayBuffer[Double](),\n",
    "    \"zTU\" -> ArrayBuffer[Double]()\n",
    "  )\n",
    "\n",
    "  while (iter < maxIter) {\n",
    "    val data = simulationCauchy(n, diff)\n",
    "    val x = data._1\n",
    "    val y = data._2\n",
    "\n",
    "    val tTestResults = TwoSample.tTest(x, y)\n",
    "    val mwUResults = TwoSample.mwU(x, y)\n",
    "    val zTUResults = TwoSample.zeroTrimmedU(x, y)\n",
    "\n",
    "    pValues(\"tTest\") += tTestResults._2\n",
    "    pValues(\"mwU\") += mwUResults._2\n",
    "    pValues(\"zTU\") += zTUResults._2\n",
    "    iter += 1\n",
    "\n",
    "    // Print progress every maxIter / 10 steps\n",
    "    if (iter % (maxIter / 10) == 0) {\n",
    "      println(s\"Iteration $iter/$maxIter completed.\")\n",
    "    }\n",
    "  }\n",
    "  // Compute the proportion of p-values less than 0.05 for each test\n",
    "  val proportions = pValues.map { case (testName, values) =>\n",
    "    testName -> values.count(_ < 0.05).toDouble / maxIter\n",
    "  }\n",
    "\n",
    "  // Print the results\n",
    "  proportions.foreach { case (testName, proportion) =>\n",
    "    println(s\"$testName: Proportion of p-values < 0.05 = $proportion\")\n",
    "  }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c13411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 completed.\n",
      "Iteration 40/200 completed.\n",
      "Iteration 60/200 completed.\n",
      "Iteration 80/200 completed.\n",
      "Iteration 100/200 completed.\n",
      "Iteration 120/200 completed.\n",
      "Iteration 140/200 completed.\n",
      "Iteration 160/200 completed.\n",
      "Iteration 180/200 completed.\n",
      "Iteration 200/200 completed.\n",
      "zTU: Proportion of p-values < 0.05 = 0.965\n",
      "tTest: Proportion of p-values < 0.05 = 0.125\n",
      "mwU: Proportion of p-values < 0.05 = 0.975\n"
     ]
    }
   ],
   "source": [
    "runSimulation(100, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528c4535-ca73-4756-bd13-577c7c2e76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 completed.\n",
      "Iteration 40/200 completed.\n",
      "Iteration 60/200 completed.\n",
      "Iteration 80/200 completed.\n",
      "Iteration 100/200 completed.\n",
      "Iteration 120/200 completed.\n",
      "Iteration 140/200 completed.\n",
      "Iteration 160/200 completed.\n",
      "Iteration 180/200 completed.\n",
      "Iteration 200/200 completed.\n",
      "zTU: Proportion of p-values < 0.05 = 0.05\n",
      "tTest: Proportion of p-values < 0.05 = 0.01\n",
      "mwU: Proportion of p-values < 0.05 = 0.03\n"
     ]
    }
   ],
   "source": [
    "runSimulation(100, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41deca2f-3457-48eb-a0ce-73232bc6716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runSimulationDf: (n: Int, diff: Double)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.Row\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "\n",
    "def runSimulationDf(n: Int, diff: Double): DataFrame = {\n",
    "  // Create Spark session\n",
    "  val spark = SparkSession.builder()\n",
    "    .appName(\"Simulation\")\n",
    "    .master(\"local[*]\") // Use local mode for simplicity\n",
    "    .getOrCreate()\n",
    "  \n",
    "  val maxIter = 200\n",
    "  var iter = 0\n",
    "  val results = ArrayBuffer[(String, Double, Double, Double)]() // Store test name, z, p-value, and U\n",
    "\n",
    "  while (iter < maxIter) {\n",
    "    val data = simulationCauchy(n, diff)\n",
    "    val x = data._1\n",
    "    val y = data._2\n",
    "\n",
    "    val tTestResults = TwoSample.tTest(x, y)\n",
    "    val mwUResults = TwoSample.mwU(x, y)\n",
    "    val zTUResults = TwoSample.zeroTrimmedU(x, y)\n",
    "\n",
    "    // Collect results for each test\n",
    "    results += ((\"tTest\", tTestResults._1, tTestResults._2, tTestResults._3))\n",
    "    results += ((\"mwU\", mwUResults._1, mwUResults._2, mwUResults._3))\n",
    "    results += ((\"zTU\", zTUResults._1, zTUResults._2, zTUResults._3))\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "    // Print progress every maxIter / 10 steps\n",
    "    if (iter % (maxIter / 10) == 0) {\n",
    "      println(s\"Iteration $iter/$maxIter completed.\")\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Create a DataFrame from the collected results\n",
    "  val schema = StructType(Seq(\n",
    "    StructField(\"TestName\", StringType, nullable = false),\n",
    "    StructField(\"Z\", DoubleType, nullable = false),\n",
    "    StructField(\"PValue\", DoubleType, nullable = false),\n",
    "    StructField(\"U\", DoubleType, nullable = false)\n",
    "  ))\n",
    "\n",
    "  val rows = results.map { case (testName, z, pValue, u) =>\n",
    "    Row(testName, z, pValue, u)\n",
    "  }\n",
    "\n",
    "  val df = spark.createDataFrame(spark.sparkContext.parallelize(rows), schema)\n",
    "  df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf03a9b-23e5-4b2a-85b6-d2076c947d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 completed.\n",
      "Iteration 40/200 completed.\n",
      "Iteration 60/200 completed.\n",
      "Iteration 80/200 completed.\n",
      "Iteration 100/200 completed.\n",
      "Iteration 120/200 completed.\n",
      "Iteration 140/200 completed.\n",
      "Iteration 160/200 completed.\n",
      "Iteration 180/200 completed.\n",
      "Iteration 200/200 completed.\n",
      "+--------+-------------------+--------------------+-------------------+\n",
      "|TestName|                  Z|              PValue|                  U|\n",
      "+--------+-------------------+--------------------+-------------------+\n",
      "|   tTest|-0.5323557414710041|  0.5944796324537083|  0.349196161828488|\n",
      "|     mwU|  3.557574219655608|3.742953640339941E-4|             0.6456|\n",
      "|     zTU| 3.5752116651613997|3.499446606261003E-4| 0.6941157133464826|\n",
      "|   tTest| 0.5116182709048532|  0.6089181956959913|-0.6397527399722434|\n",
      "|     mwU| 3.9729503304670457|7.098785602677182E-5|             0.6626|\n",
      "|     zTU|  4.125561560099488|3.698312378008772E-5| 0.7328341855368883|\n",
      "|   tTest|-0.9790661045119029|  0.3275473181444273|   3.79287224885254|\n",
      "|     mwU|  4.371222719068601|1.235526831222522E-5|             0.6789|\n",
      "|     zTU|  4.505715802273667|6.614957277717437E-6|  0.731132831277039|\n",
      "|   tTest|-0.6700662431538057|  0.5028155628211695| 0.7033422713217492|\n",
      "|     mwU|   5.73585541252853|9.702140424394656E-9|            0.73475|\n",
      "|     zTU|  6.237210835302274|4.454414614940560...| 0.8027739673830209|\n",
      "|   tTest|-1.1027636954775235|  0.2701297977693704| 1.8970003013989363|\n",
      "|     mwU|  3.039575775584874|0.002369115964070634|             0.6244|\n",
      "|     zTU|  3.450209315829238|5.601520531186566E-4| 0.7254778407897501|\n",
      "|   tTest| 0.3679081697279529|  0.7129417082881377|-1.9372985735707848|\n",
      "|     mwU|  2.783019942436633| 0.00538554957320736|             0.6139|\n",
      "|     zTU| 2.8745573222564724|0.004045943196831381| 0.6723886048210372|\n",
      "|   tTest|-0.4924844206764847|  0.6223769327575241| 0.8436902368314843|\n",
      "|     mwU|  3.765262275061327|1.663743505482262...|             0.6541|\n",
      "+--------+-------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [TestName: string, Z: double ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestName: string, Z: double ... 2 more fields]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Run the simulation and get the DataFrame\n",
    "val df = runSimulationDf(100, 1.0)\n",
    "\n",
    "// Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2feb9fe9-7373-4c3d-864e-ed29f8beb107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 completed.\n",
      "Iteration 40/200 completed.\n",
      "Iteration 60/200 completed.\n",
      "Iteration 80/200 completed.\n",
      "Iteration 100/200 completed.\n",
      "Iteration 120/200 completed.\n",
      "Iteration 140/200 completed.\n",
      "Iteration 160/200 completed.\n",
      "Iteration 180/200 completed.\n",
      "Iteration 200/200 completed.\n",
      "+--------+--------------------+-------------------+------------------+\n",
      "|TestName|                   Z|             PValue|                 U|\n",
      "+--------+--------------------+-------------------+------------------+\n",
      "|   tTest| -0.6435748352307389|  0.519851172867468|1.0639939810798402|\n",
      "|     mwU| -1.0946382214324948| 0.2736751637374537|            0.4552|\n",
      "|     zTU| -1.0166097148997475|0.30933913082668374|0.4173525377229081|\n",
      "|   tTest| -0.8636190935886839| 0.3877971717704072|0.6880614199375452|\n",
      "|     mwU| 0.31031038866501526| 0.7563249318138219|            0.5127|\n",
      "|     zTU|  0.8003568004726366| 0.4235041025061954|0.5800619834710744|\n",
      "|   tTest| -0.7543987350075011|0.45060983094618434|1.1766446220870044|\n",
      "|     mwU|0.057419638847463456|  0.954210919271917|           0.50235|\n",
      "|     zTU|-0.08512573647953428| 0.9321614298131424|0.4928925619834711|\n",
      "|   tTest| -0.8296159758527148| 0.4067559412722015|1.2919457543738533|\n",
      "|     mwU|-0.07941013883159839|   0.93670640448885|           0.49675|\n",
      "|     zTU| -0.3796377279240387| 0.7042143510294328|0.4652228238234069|\n",
      "|   tTest| -1.5001777925434465| 0.1335683541530175|24.383944171135457|\n",
      "|     mwU| 0.20035788874434057| 0.8412006915873591|            0.5082|\n",
      "|     zTU|  0.4115323560052563| 0.6806822208549579|0.5345454545454545|\n",
      "|   tTest| -0.5589221346249306|  0.576214862379965|0.2645966410762708|\n",
      "|     mwU|-0.15882027766319678| 0.8738104723211455|            0.4935|\n",
      "|     zTU|-0.17433510977385605| 0.8616021080986935|0.4844290657439446|\n",
      "|   tTest|  -1.723258188570684|0.08484184521814875|17.144725069462893|\n",
      "|     mwU|   1.359745915685677|0.17391034266178496|           0.55565|\n",
      "+--------+--------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [TestName: string, Z: double ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestName: string, Z: double ... 2 more fields]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Run the simulation and get the DataFrame\n",
    "val df = runSimulationDf(100, 0.0)\n",
    "\n",
    "// Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a63c1-8f59-4482-a983-67ede35b8788",
   "metadata": {},
   "source": [
    "## GEE (TOADD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8136a531-0750-4395-98f8-b2f6bf1f3452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@6938671e\n",
       "rand = scala.util.Random@681d89f6\n",
       "trueBeta = DenseVector(0.0, 1.0, -1.0)\n",
       "nClusters = 1000\n",
       "obsPerCluster = 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create Spark session\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"Binomial Simulation\")\n",
    "  .master(\"local[*]\") // Use local mode for simplicity\n",
    "  .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "import breeze.linalg._\n",
    "import breeze.numerics._\n",
    "import org.apache.spark.sql.Dataset\n",
    "import scala.util.Random\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.Row\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "\n",
    "val rand = new Random(123)\n",
    "val trueBeta = DenseVector(0.0, 1.0, -1.0)\n",
    "val nClusters = 1000\n",
    "val obsPerCluster = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd418bd0-355f-4d39-aa75-e42b91cf378d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simulateBinomialData: (nClusters: Int, trueBeta: breeze.linalg.DenseVector[Double])org.apache.spark.sql.Dataset[robustinfer.Obs]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "def simulateBinomialData(nClusters: Int, trueBeta: DenseVector[Double]): Dataset[robustinfer.Obs] = {\n",
    "\n",
    "  val data = (0 until nClusters).flatMap { clusterId =>\n",
    "    (0 until obsPerCluster).map { _ =>\n",
    "      val x = Array(1.0, rand.nextGaussian(), rand.nextGaussian())\n",
    "      val eta = x.zipWithIndex.map { case (xi, k) => xi * trueBeta(k) }.sum\n",
    "      val prob = 1.0 / (1.0 + math.exp(-eta))\n",
    "      val y = if (rand.nextDouble() < prob) 1.0 else 0.0\n",
    "      Obs(clusterId.toString, x.drop(1), y)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Create a DataFrame\n",
    "  val df = spark.createDataset(data)\n",
    "  df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746363e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runBinomialSimulation: (nClusters: Int, trueBeta: breeze.linalg.DenseVector[Double])org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "def runBinomialSimulation(nClusters: Int, trueBeta: DenseVector[Double]): DataFrame = {\n",
    "  val maxIter = 200\n",
    "  var iter = 0\n",
    "  val results = ArrayBuffer[(Double, Double, Double)]() // Store beta, p-value, and standard error\n",
    "  while (iter < maxIter) {\n",
    "    val df = simulateBinomialData(nClusters, trueBeta)\n",
    "    val gee = new GEE()\n",
    "    gee.fit(df, verbose = false)\n",
    "\n",
    "    // Collect results\n",
    "    val summary = gee.summary()\n",
    "    val beta1 = summary.beta(1) \n",
    "    val se = math.sqrt(summary.variance(1, 1))\n",
    "    val z = beta1 / se\n",
    "    val pValue = 2 * (1 - new org.apache.commons.math3.distribution.NormalDistribution().cumulativeProbability(math.abs(z)))\n",
    "\n",
    "    results += ((beta1, pValue, se))\n",
    "    \n",
    "    iter += 1\n",
    "\n",
    "    // Print progress every maxIter / 10 steps\n",
    "    if (iter % (maxIter / 10) == 0) {\n",
    "      println(s\"Iteration $iter/$maxIter completed.\")\n",
    "    }\n",
    "  }\n",
    "  // Calculate proportion of p-values < 0.05\n",
    "  val proportion = results.count(_._2 < 0.05).toDouble / maxIter\n",
    "  println(s\"Proportion of p-values < 0.05: $proportion\")\n",
    "\n",
    "  // Create a DataFrame from the results\n",
    "  val schema = StructType(Seq(\n",
    "    StructField(\"Beta\", DoubleType, nullable = false),\n",
    "    StructField(\"PValue\", DoubleType, nullable = false),\n",
    "    StructField(\"StandardError\", DoubleType, nullable = false)\n",
    "  ))\n",
    "\n",
    "  val rows = results.map { case (beta, pValue, se) =>\n",
    "    Row(beta, pValue, se)\n",
    "  }\n",
    "\n",
    "  spark.createDataFrame(spark.sparkContext.parallelize(rows), schema)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9740ba0d-ab8c-466c-ba12-c72c54472950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 completed.\n",
      "Iteration 40/200 completed.\n",
      "Iteration 60/200 completed.\n",
      "Iteration 80/200 completed.\n",
      "Iteration 100/200 completed.\n",
      "Iteration 120/200 completed.\n",
      "Iteration 140/200 completed.\n",
      "Iteration 160/200 completed.\n",
      "Iteration 180/200 completed.\n",
      "Iteration 200/200 completed.\n",
      "Proportion of p-values < 0.05: 0.055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "redDf0 = [Beta: double, PValue: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[Beta: double, PValue: double ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val redDf0 = runBinomialSimulation(200, DenseVector(0.0, 0.0, -1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ba83c1-c4b0-402f-8d85-9573d69837d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 completed.\n",
      "Iteration 40/200 completed.\n",
      "Iteration 60/200 completed.\n",
      "Iteration 80/200 completed.\n",
      "Iteration 100/200 completed.\n",
      "Iteration 120/200 completed.\n",
      "Iteration 140/200 completed.\n",
      "Iteration 160/200 completed.\n",
      "Iteration 180/200 completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "resDf1 = [Beta: double, PValue: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200/200 completed.\n",
      "Proportion of p-values < 0.05: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Beta: double, PValue: double ... 1 more field]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val resDf1 = runBinomialSimulation(200, DenseVector(0.0, 1.0, -1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6358b0-5418-4bfc-a827-fdbe50f6d554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree_scala - Scala",
   "language": "scala",
   "name": "apache_toree_scala_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
